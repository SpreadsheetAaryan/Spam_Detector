{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279535ab-1089-4921-9f9d-95fcae78a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ssl\n",
    "import certifi\n",
    "import tarfile\n",
    "import email\n",
    "import email.policy\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from html import unescape\n",
    "import nltk\n",
    "import urlextract\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec1ea5-a3a7-4714-9e21-00bf5b779862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_spam_data():\n",
    "    spam_root = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "    ham_url = spam_root + \"20030228_easy_ham.tar.bz2\"\n",
    "    spam_url = spam_root + \"20030228_spam.tar.bz2\"\n",
    "\n",
    "    # Setting up SSL context\n",
    "    context = ssl.create_default_context(cafile=certifi.where())\n",
    "\n",
    "    spam_path = Path(\"datasets\") / \"spam\"\n",
    "    spam_path.mkdir(parents=True, exist_ok=True)\n",
    "    for dir_name, tar_name, url in ((\"easy_ham\", \"ham\", ham_url),\n",
    "                                    (\"spam\", \"spam\", spam_url)):\n",
    "        if not (spam_path / dir_name).is_dir():\n",
    "            path = (spam_path / tar_name).with_suffix(\".tar.bz2\")\n",
    "            print(\"Downloading\", path)\n",
    "            with urllib.request.urlopen(url, context=context) as response, open(path, 'wb') as out_file:\n",
    "                out_file.write(response.read())\n",
    "            tar_bz2_file = tarfile.open(path)\n",
    "            tar_bz2_file.extractall(path=spam_path)\n",
    "            tar_bz2_file.close()\n",
    "    return [spam_path / dir_name for dir_name in (\"easy_ham\", \"spam\")]\n",
    "\n",
    "ham_dir, spam_dir = fetch_spam_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25347517-b4e7-498e-94e4-45ccdc5f83a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_filenames = [f for f in sorted(ham_dir.iterdir()) if len(f.name) > 20]\n",
    "spam_filenames = [f for f in sorted(spam_dir.iterdir()) if len(f.name) > 20]\n",
    "\n",
    "print(len(spam_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1980b2-e21b-4d9a-8c7a-9783f1f13b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_email(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)\n",
    "\n",
    "ham_emails = [load_email(filepath) for filepath in ham_filenames]\n",
    "spam_emails = [load_email(filepath) for filepath in spam_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abacbc2b-6525-451a-9b1b-b9f8e1772329",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spam_emails[1].get_content().strip())\n",
    "print(ham_emails[1].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1979993e-c5ef-4945-8d03-85dbeb68c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        multipart = \", \".join([get_email_structure(sub_email)\n",
    "                               for sub_email in payload])\n",
    "        return f\"multipart({multipart})\"\n",
    "    else:\n",
    "        return email.get_content_type()\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures\n",
    "\n",
    "print(structures_counter(ham_emails).most_common())\n",
    "structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ed8a68-5935-4ac1-8aac-cddc142f8baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(ham_emails + spam_emails, dtype=object)\n",
    "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5749577d-673c-4879-ac92-fb9fbcf396ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_plain_text(html):\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    return unescape(text)\n",
    "\n",
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except:\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "\n",
    "    if html:\n",
    "        return html_to_plain_text(html)\n",
    "\n",
    "stemmer = nltk.PorterStemmer()\n",
    "for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\",\n",
    "             \"Compulsive\"):\n",
    "    print(word, \"=>\", stemmer.stem(word))\n",
    "\n",
    "url_extractor = urlextract.URLExtract()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d1028-2c8a-400f-8143-47c4e55e6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True,\n",
    "                 remove_punctuation=True, replace_urls=True,\n",
    "                 replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c4fa6-2c77-44bc-a5ad-0bc56ae36620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.vocabulary_ = {word: index + 1\n",
    "                            for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)),\n",
    "                          shape=(len(X), self.vocabulary_size + 1))\n",
    "\n",
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "X_few_vectors = vocab_transformer.fit_transform(EmailToWordCounterTransformer().fit_transform(x_train[:3]))\n",
    "X_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78792d2-1889-4fe6-aea6-e90aad993074",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Pipeline([\n",
    "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
    "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
    "    (\"logistic_regressor\", LogisticRegression(max_iter=1000, random_state=42)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71506689-fb02-483d-a94b-ce136af9ed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(final_model, x_train, y_train, cv=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be40ac-9f28-4050-869c-b4f36b82278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.fit(x_train, y_train)\n",
    "y_pred = final_model.predict(x_test)\n",
    "\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.2%}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.2%}\")\n",
    "\n",
    "# precision and recall both over 95 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc09ee-9eba-4af0-baad-30f1c4bd5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(final_model, \"spam_detector_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e883e2-3b84-4918-9642-f8ce445c5eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_reloaded = joblib.load(\"spam_detector_model.pkl\")\n",
    "\n",
    "new_data = x_train[:30]  # pretend these are new emails\n",
    "predictions = final_model_reloaded.predict(new_data)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
